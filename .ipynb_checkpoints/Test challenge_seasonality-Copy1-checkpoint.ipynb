{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.signal as sgn\n",
    "import scipy.stats as stat\n",
    "import matplotlib.gridspec as grds\n",
    "\n",
    "\n",
    "import statsmodels.tsa.stattools as sta\n",
    "\n",
    "% matplotlib qt\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "data = pd.read_csv('challenge-data-v2.csv', index_col='event_date',parse_dates = True)\n",
    "\n",
    "\n",
    "# Taking a look into the first elements of the data to know more about the structure\n",
    "data.head()\n",
    "\n",
    "# Changing the name of the colums to a more suitable (shorter) form\n",
    "data.columns = ['sups','moff','mon','hd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sups</th>\n",
       "      <th>moff</th>\n",
       "      <th>mon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1155.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>1155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8054.577489</td>\n",
       "      <td>98884.865284</td>\n",
       "      <td>334811.893541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2093.419767</td>\n",
       "      <td>71107.830804</td>\n",
       "      <td>152979.099583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3973.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40243.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6657.500000</td>\n",
       "      <td>55285.487500</td>\n",
       "      <td>234232.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7639.000000</td>\n",
       "      <td>84413.085000</td>\n",
       "      <td>314120.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8967.500000</td>\n",
       "      <td>123233.000000</td>\n",
       "      <td>430718.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26348.000000</td>\n",
       "      <td>446191.350000</td>\n",
       "      <td>975192.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sups           moff            mon\n",
       "count   1155.000000     282.000000    1155.000000\n",
       "mean    8054.577489   98884.865284  334811.893541\n",
       "std     2093.419767   71107.830804  152979.099583\n",
       "min     3973.000000       0.000000   40243.090000\n",
       "25%     6657.500000   55285.487500  234232.175000\n",
       "50%     7639.000000   84413.085000  314120.800000\n",
       "75%     8967.500000  123233.000000  430718.990000\n",
       "max    26348.000000  446191.350000  975192.300000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sups\n",
      "The feature: sups was rescaled by a factor of 10000.0\n",
      "moff\n",
      "The feature: moff was rescaled by a factor of 100000.0\n",
      "mon\n",
      "The feature: mon was rescaled by a factor of 1000000.0\n"
     ]
    }
   ],
   "source": [
    "for feature in data.columns:\n",
    "    if data[feature].values.dtype != 'object':\n",
    "        print feature\n",
    "        scale_factor = np.round(np.log10(np.mean(data[feature])))\n",
    "        data[feature] = data[feature] / 10**scale_factor\n",
    "        print 'The feature: '+feature+' was rescaled by a factor of '+str(10**scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'sups', u'moff', u'mon'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sups</th>\n",
       "      <th>moff</th>\n",
       "      <th>mon</th>\n",
       "      <th>hd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>0.4246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041934</td>\n",
       "      <td>NewYearsDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>0.6569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054117</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>0.7466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051634</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-04</th>\n",
       "      <td>0.6911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047323</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-05</th>\n",
       "      <td>0.5929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048324</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sups  moff       mon           hd\n",
       "event_date                                     \n",
       "2014-01-01  0.4246   NaN  0.041934  NewYearsDay\n",
       "2014-01-02  0.6569   NaN  0.054117          NaN\n",
       "2014-01-03  0.7466   NaN  0.051634          NaN\n",
       "2014-01-04  0.6911   NaN  0.047323          NaN\n",
       "2014-01-05  0.5929   NaN  0.048324          NaN"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some statistics\n",
    "print data.columns[data.columns!='hd']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1) \t CORRELATION \t\n",
    "    -Q1.1) Using Python and the libraries and packages of your own choice, write a well-structured and readable program that can be used to analyse the data set for correlations between the time series. The program should work with data files that are similar, but not necessarily identical to the sample provided. Your response should include the program itself and brief instructions about any dependencies that should be installed before running it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposal\n",
    "\n",
    "For answering this question I have programmed a python file called \"BW7_toolbox.py\" that is attached in my submission. This file contains two functions: correlation_study and seasons_study. Each one is the answer for each of the question suggested in the case of study. In the same project there is also a __init__ file just for the sake of generating a python package.\n",
    "\n",
    "To execute the functions just unzip the file in the folder where regularly is used as a python path and use \"import BW7_toolbox as BW7\" to add it to your project. Once in your project you could call the evaluation of the solutions as BW7.correlation_study(filename) or BW7.seasons_study(filename). By default the data for this case of study will be loaded but any csv file that is in the same folder that the python files coudl be also used just by using the proper filename (with the csv extension as part of the name). \n",
    "\n",
    "The idea behind the solution of this firs question is to provide the user the most usefol plots and information to observe any correlation. With that in mind after the execution of \"correlation_study\" the next plots will be presented on the screen (different windows):\n",
    "* Temporal distribution by year. The idea of this plot is to provide the user a broad overview of the activity of the different features. For that reason each feature has assigned one colum while the rows represent different distributions:\n",
    "    * First row, distribution of features accross the year for different years.\n",
    "    * Second row, distribution of the features per month for different years. \n",
    "    * Third row, distribution of the featyres during the weekdays for different years. \n",
    "\n",
    "* Monthly distribution of features. In this plot I present the monthly distribution of the different features. The idea here is to provide some insight into the data before the next plot. \n",
    "* Monthly features crosscorrelations. This plot address explicitly the question of the correlation between the different time series of the data set in the temporal scale of a month. I did it in this way to address that the data is non-stationary and hence this relationship depends strongly of the period of the year (month). Take in account that the first zero lag is from the first time series mentioned in the plot to the second. Then if you observed a peak in the positive side of the crosscorrelograms should be interpreted as a larger probability of having the event two in that lag of time respect the first time series mentioned in the plot. The cross correlations are computed to have the same number of samples than the original time series (I find a 'full' version non informative in this time scale). Whenever you find an empty plot is because there was not enough collected data to calculate any statistics. \n",
    "\n",
    "* Rolling corelation coefficient and weekly activity of the different features. In my opinion this is the more informative than the previous one but address the problem a bit different. This figure shows the moving correlation coefficient (with a temporal window of 14 days, 2 weeks) together with the dynamics of the features (resampled to weekly activity for the sake of smooth it). Interestingly in this way it is possible to extract some statistics on what it is going with this coefficient divided by years. This is shown in the last row of the plot. This row presents the distributions of the correlations during the year and provide a nice picture of the business choices taken during that year. It also measure the effectiveness of whatever event because this will have an impact in the shape and other moments of those distributions. The median (assuming that in general the situation wont be gaussian) is shown as a parameter for decision making (or index of correlation for a year). In the cases the skweness of the distribution is close to a gaussian, a normal distribution will be fitted to the data (and the mean and variance of the distribution will be shown). In addition to this in the console there will be reflected also the activity of the different moments of the distributions per year. \n",
    "\n",
    "These plots are just tools, a window to the observer to have an insight on what it is happening with the correlation of the features. \n",
    "\n",
    "Non-numeric features will not be considered for this study. That is the reason for discarding (not using) the holydays.\n",
    "\n",
    "In the next cells I present the same code that is used in the function that will help in the reporting of the specific case of study.\n",
    "\n",
    "There is some redundancy in the code but this was done with the idea of reusability of blocks of code, not only for me but for other developers too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirota/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:27: FutureWarning: \n",
      ".resample() is now a deferred operation\n",
      "You called values(...) on this deferred object which materialized it into a series\n",
      "by implicitly taking the mean.  Use .resample(...).mean() instead\n"
     ]
    }
   ],
   "source": [
    "# *****************************************************\n",
    "# Computation of the distributions per year for the different features\n",
    "years = np.unique(data.index.year)\n",
    "\n",
    "\n",
    "# Definition of the figure.\n",
    "figid = plt.figure('Temporal distributions by year', figsize=(20, 10))\n",
    "\n",
    "# Definition of the matrix of plots. In this case the situation is more complex that is why I need to define a\n",
    "# matrix. It will be a dim[2x3] matrix.\n",
    "col = len(data.columns[data.columns!='hd'])\n",
    "gs = grds.GridSpec(3,col)\n",
    "\n",
    "for i in range(col):\n",
    "    \n",
    "    ax1 = plt.subplot(gs[0, i])\n",
    "    ax2 = plt.subplot(gs[1,i])\n",
    "    \n",
    "    legend =[]\n",
    "    for y in years:\n",
    "        dat = data[data.columns[i]][str(y)].values\n",
    "        ax1.plot(np.arange(len(dat)),dat,'-')\n",
    "        legend.append(str(y))\n",
    "    ax1.legend(legend)\n",
    "    ax1.set_title('Daily '+data.columns[i])\n",
    "\n",
    "    legend =[]\n",
    "    for y in years:\n",
    "        dat = data[data.columns[i]][str(y)].resample('M').values\n",
    "        ax2.plot(np.arange(len(dat))+1,dat,'-o')\n",
    "        legend.append(str(y))\n",
    "    ax2.legend(legend)\n",
    "    ax2.set_title('Monthly '+data.columns[i])\n",
    "    plt.xlim([1,12])\n",
    "\n",
    "    ax3 = plt.subplot(gs[2,i])\n",
    "    legend =[]\n",
    "    for y in years:\n",
    "        dat = data[data.columns[i]][str(y)]\n",
    "#         dat = dat.groupby(data.index.dayofweek).mean()\n",
    "        dat = dat.groupby(dat.index.dayofweek).mean()\n",
    "        dat.index=['Mon','Tues','Wed','Thurs','Fri','Sat','Sun']\n",
    "        dat.plot(style='-o')\n",
    "        legend.append(str(y))\n",
    "    ax3.legend(legend)\n",
    "    ax3.set_title('Day week '+data.columns[i])\n",
    "\n",
    "# print data.index.strftime('%A')\n",
    "\n",
    "# sup['2015'].plot(ax=ax)\n",
    "# sup['2016'].plot(ax=ax)\n",
    "# sup['2017'].plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# *****************************************************\n",
    "# Computation of the distribution of activity per month for the different time series that are present in the data\n",
    "years = np.unique(data.index.year)\n",
    "\n",
    "\n",
    "# Definition of the figure.\n",
    "figid = plt.figure('Monthly distribution of features',figsize=(20, 10))\n",
    "\n",
    "# Definition of the matrix of plots. In this case the situation is more complex that is why I need to define a\n",
    "# matrix. It will be a dim[2x3] matrix.\n",
    "col = len(data.columns[data.columns!='hd'])\n",
    "rows = len(years) \n",
    "gs = grds.GridSpec(rows,col)\n",
    "months=['Jan','Feb','Mar','Aprl','May','Jun','Jul','Agst','Sep','Oct','Nov','Dec']\n",
    "colors = sns.hls_palette(12, l=.5, s=.6)\n",
    "\n",
    "for c in range(col):\n",
    "    for r in range(rows):\n",
    "        ax1 = plt.subplot(gs[r, c])\n",
    "\n",
    "        dat_year = data[data.columns[c]][str(years[r])]\n",
    "\n",
    "        for m in range(1,13):\n",
    "#             print m\n",
    "            dat = dat_year[dat_year.index.month==m].values\n",
    "            ax1.plot(np.arange(len(dat)),dat,'-', color=colors[m-1])\n",
    "        if r==0 and c==col-1:\n",
    "            ax1.legend(months, bbox_to_anchor=(1, 1), loc='upper left', borderaxespad=0.,ncol=2, fancybox=True,frameon=True)\n",
    "  \n",
    "        if c==0:\n",
    "            ax1.set_ylabel('Year: '+str(years[r]))\n",
    "            \n",
    "        if r==0:\n",
    "            ax1.set_title('Feature: '+str(data.columns[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# *****************************************************\n",
    "# Computation of the distribution of cross correlations per month for the different time series that are present in the data\n",
    "years = np.unique(data.index.year)\n",
    "\n",
    "\n",
    "# Definition of the figure.\n",
    "figid = plt.figure('Monthly features cross-correlations', figsize=(20, 10))\n",
    "\n",
    "# Definition of the matrix of plots.\n",
    "feature1 =[0,0,2]\n",
    "feature2= [2,1,1]\n",
    "\n",
    "col = len(data.columns[data.columns!='hd'])\n",
    "rows = len(years) \n",
    "\n",
    "gs = grds.GridSpec(rows,col)\n",
    "months=['Jan','Feb','Mar','Aprl','May','Jun','Jul','Agst','Sep','Oct','Nov','Dec']\n",
    "# colors = sns.color_palette(\"Set2\", 12)\n",
    "colors = sns.hls_palette(12, l=.5, s=.6)\n",
    "\n",
    "for c in range(col):\n",
    "    for r in range(rows):\n",
    "        ax1 = plt.subplot(gs[r, c])\n",
    "\n",
    "        dat_year_feat1 = data[data.columns[feature1[c]]][str(years[r])]\n",
    "        dat_year_feat2 = data[data.columns[feature2[c]]][str(years[r])]\n",
    "        \n",
    "        for m in range(1,13):\n",
    "            dat_feat1 = dat_year_feat1[dat_year_feat1.index.month==m].values\n",
    "            dat_feat1= np.subtract(dat_feat1,np.mean(dat_feat1))\n",
    "            dat_feat2 = dat_year_feat2[dat_year_feat2.index.month==m].values\n",
    "            dat_feat2= np.subtract(dat_feat2,np.mean(dat_feat2))\n",
    "            dat = sgn.correlate(dat_feat1,dat_feat2,mode='same')\n",
    "            ax1.plot(np.linspace(-15,15,len(dat)),dat,'-', color=colors[m-1])\n",
    "        if c==0:\n",
    "            ax1.set_ylabel('Year: '+str(years[r]))\n",
    "        if r==0 and c==col-1:\n",
    "            ax1.legend(months, bbox_to_anchor=(1, 1), loc='upper left', borderaxespad=0.,ncol=2, fancybox=True,frameon=True)\n",
    "        if r==0:\n",
    "            ax1.set_title('Xcorr: '+str(data.columns[feature1[c]])+' and '+str(data.columns[feature2[c]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirota/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n",
      "/home/sirota/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/home/sirota/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:116: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Xcorr normalizing the variance\n",
    "\n",
    "years = np.unique(data.index.year)\n",
    "\n",
    "\n",
    "# Definition of the figure.\n",
    "figid = plt.figure(5,figsize=(20, 10))\n",
    "\n",
    "# Definition of the matrix of plots.\n",
    "feature1 =[0,0,2]\n",
    "feature2= [2,1,1]\n",
    "\n",
    "col = len(data.columns[data.columns!='hd'])\n",
    "rows = len(years) \n",
    "\n",
    "gs = grds.GridSpec(rows,col)\n",
    "months=['Jan','Feb','Mar','Aprl','May','Jun','Jul','Agst','Sep','Oct','Nov','Dec']\n",
    "colors = sns.hls_palette(12, l=.5, s=.6)\n",
    "\n",
    "for c in range(col):\n",
    "    for r in range(rows):\n",
    "        ax1 = plt.subplot(gs[r, c])\n",
    "\n",
    "        dat_year_feat1 = data[data.columns[feature1[c]]][str(years[r])]\n",
    "        dat_year_feat2 = data[data.columns[feature2[c]]][str(years[r])]\n",
    "        \n",
    "        for m in range(1,13):\n",
    "            dat_feat1 = dat_year_feat1[dat_year_feat1.index.month==m].values\n",
    "            dat_feat1= np.subtract(dat_feat1,np.mean(dat_feat1))/np.var(dat_feat2)\n",
    "            dat_feat2 = dat_year_feat2[dat_year_feat2.index.month==m].values\n",
    "            dat_feat2= np.subtract(dat_feat2,np.mean(dat_feat2))/np.var(dat_feat2)\n",
    "            dat = sgn.correlate(dat_feat1,dat_feat2,mode='same')\n",
    "            ax1.plot(np.linspace(-15,15,len(dat)),dat,'-', color=colors[m-1])\n",
    "        if c==0:\n",
    "            ax1.set_ylabel('Year: '+str(years[r]))\n",
    "        if r==0 and c==col-1:\n",
    "            ax1.legend(months, bbox_to_anchor=(1, 1), loc='upper left', borderaxespad=0.,ncol=2, fancybox=True,frameon=True)\n",
    "        if r==0:\n",
    "            ax1.set_title('Xcorr: '+str(data.columns[feature1[c]])+' and '+str(data.columns[feature2[c]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Monthly correlations Xcorr\n",
    "\n",
    "years = np.unique(data.index.year)\n",
    "\n",
    "\n",
    "# Definition of the figure.\n",
    "figid = plt.figure(6,figsize=(20, 10))\n",
    "\n",
    "# Definition of the matrix of plots.\n",
    "feature1 =[0]\n",
    "feature2= [2]\n",
    "\n",
    "col = len(feature1)\n",
    "rows = len(years) \n",
    "\n",
    "\n",
    "gs = grds.GridSpec(rows,col)\n",
    "months=['Jan','Feb','Mar','Aprl','May','Jun','Jul','Agst','Sep','Oct','Nov','Dec']\n",
    "# colors = sns.color_palette(\"Set2\", 12)\n",
    "colors = sns.hls_palette(12, l=.5, s=.6)\n",
    "\n",
    "\n",
    "for c in range(col):\n",
    "    for r in range(rows):\n",
    "\n",
    "        dat_year_feat1 = data[data.columns[feature1[c]]][str(years[r])]\n",
    "        dat_year_feat2 = data[data.columns[feature2[c]]][str(years[r])]\n",
    "        \n",
    "        for m in range(1,13):\n",
    "            dat_feat1 = dat_year_feat1[dat_year_feat1.index.month==m].values\n",
    "#             dat_feat1= np.subtract(dat_feat1,np.mean(dat_feat1))\n",
    "            dat_feat2 = dat_year_feat2[dat_year_feat2.index.month==m].values\n",
    "#             dat_feat2= np.subtract(dat_feat2,np.mean(dat_feat2))\n",
    "#             print type(dat_feat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.268050524256\n"
     ]
    }
   ],
   "source": [
    "x=np.arange(100)\n",
    "y=np.sin(x)\n",
    "\n",
    "dat_year_feat1 = data['sups']['2014']\n",
    "dat_year_feat2 = data['mon']['2014']\n",
    "            \n",
    "dat_feat1 = dat_year_feat1[dat_year_feat1.index.month==1].values\n",
    "dat_feat2 = dat_year_feat2[dat_year_feat2.index.month==1].values\n",
    "\n",
    "y=dat_feat1\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(tsa.stattools.ccovf(dat_feat1,dat_feat2))\n",
    "\n",
    "\n",
    "temp =sgn.correlate(np.subtract(dat_feat1,np.mean(dat_feat1)),np.subtract(dat_feat2,np.mean(dat_feat2)),mode='full')\n",
    "plt.figure(2)\n",
    "plt.plot(temp)\n",
    "\n",
    "print data['sups']['2014'].corr(data['mon']['2014'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirota/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:27: FutureWarning: pd.rolling_corr is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=14).corr(other=<Series>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Correlation distribution for year 2014\n",
      "Mean: 0.532746314132\n",
      "Median: 0.557949258656\n",
      "Standard deviation: 0.215720671611\n",
      "Kurtosis: -0.0421423527986\n",
      "Skewness: -0.638196099596\n",
      "Normal distribution fitted!\n",
      "mu=0.532746314132\n",
      "sigma=0.215414032264\n",
      "-------------------------------------------------\n",
      "Correlation distribution for year 2015\n",
      "Mean: 0.56389935887\n",
      "Median: 0.635166988321\n",
      "Standard deviation: 0.259349079152\n",
      "Kurtosis: 0.449585874115\n",
      "Skewness: -1.00510390293\n",
      "-------------------------------------------------\n",
      "Correlation distribution for year 2016\n",
      "Mean: 0.378524397416\n",
      "Median: 0.417440043375\n",
      "Standard deviation: 0.326511914571\n",
      "Kurtosis: 0.0600812000593\n",
      "Skewness: -0.535276902702\n",
      "Normal distribution fitted!\n",
      "mu=0.378524397416\n",
      "sigma=0.326049105104\n",
      "-------------------------------------------------\n",
      "Correlation distribution for year 2017\n",
      "Mean: 0.407220906323\n",
      "Median: 0.435383118459\n",
      "Standard deviation: 0.197383216262\n",
      "Kurtosis: -0.00269736097952\n",
      "Skewness: -0.699672583569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirota/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/home/sirota/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Correlation distribution for year 2014\n",
      "Mean: nan\n",
      "Median: nan\n",
      "Standard deviation: nan\n",
      "Kurtosis: nan\n",
      "Skewness: nan\n",
      "-------------------------------------------------\n",
      "Correlation distribution for year 2015\n",
      "Mean: nan\n",
      "Median: nan\n",
      "Standard deviation: nan\n",
      "Kurtosis: nan\n",
      "Skewness: nan\n",
      "-------------------------------------------------\n",
      "Correlation distribution for year 2016\n",
      "Mean: 0.0667764147975\n",
      "Median: 0.0597625619621\n",
      "Standard deviation: 0.305620922964\n",
      "Kurtosis: 0.359789556375\n",
      "Skewness: -0.277127492116\n",
      "Normal distribution fitted!\n",
      "mu=0.0667764147975\n",
      "sigma=0.304892385758\n",
      "-------------------------------------------------\n",
      "Correlation distribution for year 2017\n",
      "Mean: 0.0586522881211\n",
      "Median: 0.00137535800231\n",
      "Standard deviation: 0.249063699487\n",
      "Kurtosis: -0.205005171739\n",
      "Skewness: 0.743828219699\n",
      "-------------------------------------------------\n",
      "Correlation distribution for year 2014\n",
      "Mean: nan\n",
      "Median: nan\n",
      "Standard deviation: nan\n",
      "Kurtosis: nan\n",
      "Skewness: nan\n",
      "-------------------------------------------------\n",
      "Correlation distribution for year 2015\n",
      "Mean: nan\n",
      "Median: nan\n",
      "Standard deviation: nan\n",
      "Kurtosis: nan\n",
      "Skewness: nan\n",
      "-------------------------------------------------\n",
      "Correlation distribution for year 2016\n",
      "Mean: 0.0953310356165\n",
      "Median: 0.125141885314\n",
      "Standard deviation: 0.291574952557\n",
      "Kurtosis: -0.247701590368\n",
      "Skewness: -0.385902341337\n",
      "Normal distribution fitted!\n",
      "mu=0.0953310356165\n",
      "sigma=0.290879898046\n",
      "-------------------------------------------------\n",
      "Correlation distribution for year 2017\n",
      "Mean: -0.126156754847\n",
      "Median: -0.0595728797088\n",
      "Standard deviation: 0.429693681993\n",
      "Kurtosis: -1.05975389502\n",
      "Skewness: -0.149630819619\n",
      "Normal distribution fitted!\n",
      "mu=-0.126156754847\n",
      "sigma=0.424997435171\n"
     ]
    }
   ],
   "source": [
    "years = np.unique(data.index.year)\n",
    "\n",
    "# Definition of the matrix of plots.\n",
    "feature1 = [0,0,2]\n",
    "feature2 = [2,1,1]\n",
    "\n",
    "for f in range(len(feature1)):\n",
    "\n",
    "    figid = plt.figure(\n",
    "        'Rolling correlation coefficient and weekly activity of ' + data.columns[feature1[f]] + ' and ' + data.columns[\n",
    "            feature2[f]], figsize=(20, 10))\n",
    "    rows = len(years)\n",
    "\n",
    "    gs = grds.GridSpec(4, 4)\n",
    "\n",
    "    for r in range(rows):\n",
    "        ax1 = plt.subplot(gs[0, :])\n",
    "        ax2 = plt.subplot(gs[1, :])\n",
    "        ax3 = plt.subplot(gs[2, :])\n",
    "\n",
    "        dat_year_feat1 = data[data.columns[feature1[f]]][str(years[r])]\n",
    "        dat_year_feat2 = data[data.columns[feature2[f]]][str(years[r])]\n",
    "\n",
    "        ref = ax1.plot(dat_year_feat1.resample('W'))\n",
    "        ax2.plot(dat_year_feat2.resample('W'))\n",
    "\n",
    "        xcorr = pd.rolling_corr(dat_year_feat1, dat_year_feat2, 14)\n",
    "        ax3.plot(xcorr)\n",
    "\n",
    "        ax4 = plt.subplot(gs[3, r])\n",
    "        n, bins, patches = ax4.hist(xcorr.values[np.logical_not(np.isnan(xcorr.values))], bins=np.round(len(xcorr) / 6),\n",
    "                                    facecolor=ref[0].get_color(), edgecolor=ref[0].get_color())\n",
    "        mediana = ax4.axvline(np.median(xcorr.values[np.logical_not(np.isnan(xcorr.values))]), color='r', linestyle='--')\n",
    "        ax4.set_xlim([-1, 1])\n",
    "        ax4.set_xlabel('CorrCoef year '+str(years[r]))\n",
    "        ax4.set_label(mediana)\n",
    "\n",
    "        print '-------------------------------------------------'\n",
    "        print 'Correlation distribution for year ' + str(years[r])\n",
    "        print 'Mean:', xcorr.mean()\n",
    "        print 'Median:', xcorr.median()\n",
    "        print 'Standard deviation:', xcorr.std()\n",
    "        print 'Kurtosis:', xcorr.kurtosis()  # Kurtosis is mainly related with outliers not with the central peak\n",
    "        print 'Skewness:', xcorr.skew() #Take in account that this value has not the substraction of the skew of a normal distribution (3)\n",
    "\n",
    "        if (np.abs(xcorr.skew())) < 0.65:\n",
    "            mu, sigma = stat.norm.fit(xcorr.values[np.logical_not(np.isnan(xcorr.values))])\n",
    "            print 'Normal distribution fitted!'\n",
    "            print 'mu=' + str(mu)\n",
    "            print 'sigma=' + str(sigma)\n",
    "\n",
    "            fitted_normal = mlab.normpdf(bins, mu, sigma) * np.max(\n",
    "                xcorr.values[np.logical_not(np.isnan(xcorr.values))])\n",
    "            # print fitted_normal\n",
    "            normfit = ax4.plot(bins, fitted_normal * np.max(n), 'r--', linewidth=2, color=\"#3498db\")\n",
    "            ax4.legend(['Median '+str(round(xcorr.median(),2)), 'N(' + str(round(mu, 1)) + ',' + str(round(sigma, 2)) + ')'], loc='best')\n",
    "        else:\n",
    "            ax4.legend(['Median '+str(round(xcorr.median(),2))], loc='best')\n",
    "\n",
    "\n",
    "    ax1.set_ylabel(data.columns[feature1[f]])\n",
    "    ax2.set_ylabel(data.columns[feature2[f]])\n",
    "    ax3.set_ylabel('Rolling correlation, 14 days period')\n",
    "\n",
    "\n",
    "    ax1.legend(years, bbox_to_anchor=(1, 1), loc='upper left', borderaxespad=0., ncol=1, fancybox=True, frameon=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.mlab as mlab\n",
    "\n",
    "x= xcorr.values[np.logical_not(np.isnan(xcorr.values))]\n",
    "\n",
    "plt.figure()\n",
    "n, bins, patches = plt.hist(x, normed=1, facecolor='green', alpha=0.75)\n",
    "\n",
    "# add a 'best fit' line\n",
    "y = mlab.normpdf( bins, mu, sigma)\n",
    "l = plt.plot(bins, y, 'r--', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirota/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:29: FutureWarning: pd.rolling_corr is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=14).corr(other=<Series>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fb4786b1c10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = np.unique(data.index.year)\n",
    "\n",
    "\n",
    "# Definition of the figure.\n",
    "figid = plt.figure(8,figsize=(20, 10))\n",
    "\n",
    "# Definition of the matrix of plots.\n",
    "feature1 = 0\n",
    "feature2= 1\n",
    "\n",
    "rows = len(years) \n",
    "\n",
    "gs = grds.GridSpec(3,1)\n",
    "\n",
    "\n",
    "for r in range(rows):\n",
    "    ax1 = plt.subplot(gs[0, 0])\n",
    "    ax2 = plt.subplot(gs[1, 0])\n",
    "    ax3 = plt.subplot(gs[2, 0])\n",
    "    \n",
    "    dat_year_feat1 = data[data.columns[feature1]][str(years[r])]\n",
    "    dat_year_feat2 = data[data.columns[feature2]][str(years[r])]\n",
    "    \n",
    "    if np.all(np.isnan(dat_year_feat2)):\n",
    "        continue\n",
    "\n",
    "    ax1.plot(dat_year_feat1.resample('W'))\n",
    "    ax2.plot(dat_year_feat2.resample('W'))\n",
    "    ax3.plot(pd.rolling_corr(dat_year_feat1,dat_year_feat2,14))\n",
    "    \n",
    "\n",
    "ax1.set_ylabel(data.columns[feature1])\n",
    "ax2.set_ylabel(data.columns[feature2])\n",
    "ax3.set_ylabel('Rolling correlation, 14 days period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "print type(data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print tsa.stattools.periodogram(dat_feat1)\n",
    "plt.figure(3)\n",
    "plt.plot(tsa.stattools.periodogram(dat_feat1))\n",
    "\n",
    "spe = np.fft.fft(dat_feat1)\n",
    "spe = np.abs(spe)\n",
    "plt.figure(4)\n",
    "plt.plot(spe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Q1) \t CORRELATION \t\n",
    "    -Q1.1) Using Python and the libraries and packages of your own choice, write a well-structured and readable program that can be used to analyse the data set for correlations between the time series. The program should work with data files that are similar, but not necessarily identical to the sample provided. Your response should include the program itself and brief instructions about any dependencies that should be installed before running it.\n",
    "\n",
    "    -Q1.2) Run the program on the provided data sample from PetFood and comment on the output.\n",
    "\n",
    "    -Q1.3) Comment on additional approaches that could be used to search for various types of correlations in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2) SEASONS AND CYCLES \t\n",
    "    -Q2.1) Using Python and the libraries and packages of your own choice, write\ta well-structured and readable program that can be used to identify periodic behaviour in the “signups” time series. The program should work with data files that are similar, but not necessarily identical to the sample provided. Your response should include the program itself and brief instructions about any dependencies that should be installed to run it.\n",
    "\n",
    "    -Q2.2) Run the program on the data sample from PetFood, and comment on the output\n",
    "\n",
    "    -Q2.3) Discuss any additional methods and data sources that would be useful to improve the detection\tof cycles in the number\tof signups.\n",
    "\n",
    "    -Q2.4) Discuss to what degree this same code solution can be expected to\twork for a completely different customer, selling a\tcompletely different product, in a different market. Would the approach\tneed to be adjusted to accommodate such a general setting?\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
